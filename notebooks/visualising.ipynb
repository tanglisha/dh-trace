{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## todo\n",
    "\n",
    "\n",
    " 1. Improve process for generating alignments and automate that in one full script to Rule Them All\n",
    " 1. document and lock sequence alignment version, or add management to keep up to date with repo\n",
    " 1. Improve logistic regression by adding thresholds and finding the correct ones for same author.\n",
    " 1. regenerate all data\n",
    " 1. Does changing sequence alignment base ngrams from 3 to 4 or 5 matter in the logistic regression?\n",
    " 1. does stripping punctuation and capitalization from the alignments or from text matter?\n",
    " 1. Tighten the threshold window down to 1%. (may  not be relevant, because logistic regression will give precise value)\n",
    " 1. Run the code against different authors. \n",
    " 1. Does the damn thing work?\n",
    " 1. annotate edges in dataset\n",
    " 1. fully remove and document removal of n-grams (legacy and outdated code cleanup)\n",
    " 1. display more easy to see\n",
    " 1. moving to dissertation; initial check against tarah's dataset\n",
    " 1. do full relevant close re-reading\n",
    "\n",
    " DONE\n",
    "\n",
    " 1. Use Pickle or CSV to store values from dataframes so they don't have to be continuously regenerated. \n",
    " 1. Are graphs showing actual human behavior?\n",
    " 1. Full dataset working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:32.443126Z",
     "iopub.status.busy": "2024-05-01T15:11:32.442493Z",
     "iopub.status.idle": "2024-05-01T15:11:33.443416Z",
     "shell.execute_reply": "2024-05-01T15:11:33.443083Z",
     "shell.execute_reply.started": "2024-05-01T15:11:32.443095Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import networkx as nx\n",
    "#import matplotlib.pyplot as plt\n",
    "from ipycytoscape import CytoscapeWidget\n",
    "from sqlite3 import OperationalError\n",
    "from contextlib import suppress\n",
    "import ipywidgets as widgets\n",
    "from pprint import pprint\n",
    "import py4cytoscape as p4c\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:33.444241Z",
     "iopub.status.busy": "2024-05-01T15:11:33.444097Z",
     "iopub.status.idle": "2024-05-01T15:11:33.447205Z",
     "shell.execute_reply": "2024-05-01T15:11:33.446735Z",
     "shell.execute_reply.started": "2024-05-01T15:11:33.444232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('..')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working = Path('..')\n",
    "working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:33.503467Z",
     "iopub.status.busy": "2024-05-01T15:11:33.503259Z",
     "iopub.status.idle": "2024-05-01T15:11:33.620880Z",
     "shell.execute_reply": "2024-05-01T15:11:33.620346Z",
     "shell.execute_reply.started": "2024-05-01T15:11:33.503448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tarahmarie/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:34.435305Z",
     "iopub.status.busy": "2024-05-01T15:11:34.434891Z",
     "iopub.status.idle": "2024-05-01T15:11:34.570361Z",
     "shell.execute_reply": "2024-05-01T15:11:34.569692Z",
     "shell.execute_reply.started": "2024-05-01T15:11:34.435272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE                   hapaxes_1tM.py            make_dash.py\n",
      "Project History.pdf       init_db.py                make_histogram.py\n",
      "README.md                 load_alignments.py        make_jumbo_dash.py\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m               load_authors_and_texts.py make_lines.py\n",
      "\u001b[34march\u001b[m\u001b[m                      load_hapax_intersects.py  \u001b[34mnotebooks\u001b[m\u001b[m\n",
      "authors.txt               load_hapaxes.py           poetry.lock\n",
      "auto_author_prediction.py load_jaccard.py           predict_ops.py\n",
      "\u001b[31mbegin.sh\u001b[m\u001b[m                  load_ngram_intersects.py  \u001b[34mprojects\u001b[m\u001b[m\n",
      "database_ops.py           load_ngrams.py            pyproject.toml\n",
      "diagrams.ipynb            load_relationships.py     requirements.txt\n",
      "do_svm.py                 make_3d_plot.py           show_previous_averages.py\n",
      "\u001b[31mdo_viz.sh\u001b[m\u001b[m                 make_auto_scatterplot.py  util.py\n",
      "\u001b[34mexplore\u001b[m\u001b[m                   make_confusion.py         \u001b[34mutils\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls $working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:34.908668Z",
     "iopub.status.busy": "2024-05-01T15:11:34.908249Z",
     "iopub.status.idle": "2024-05-01T15:11:34.912949Z",
     "shell.execute_reply": "2024-05-01T15:11:34.912005Z",
     "shell.execute_reply.started": "2024-05-01T15:11:34.908627Z"
    }
   },
   "outputs": [],
   "source": [
    "things = working.glob('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:35.257982Z",
     "iopub.status.busy": "2024-05-01T15:11:35.257664Z",
     "iopub.status.idle": "2024-05-01T15:11:35.262368Z",
     "shell.execute_reply": "2024-05-01T15:11:35.261876Z",
     "shell.execute_reply.started": "2024-05-01T15:11:35.257960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../make_dash.py\n",
      "../database_ops.py\n",
      "../diagrams.ipynb\n",
      "../.DS_Store\n",
      "../LICENSE\n",
      "../requirements.txt\n",
      "../make_lines.py\n",
      "../util.py\n",
      "../auto_author_prediction.py\n",
      "../make_confusion.py\n",
      "../projects\n",
      "../pyproject.toml\n",
      "../predict_ops.py\n",
      "../load_jaccard.py\n",
      "../do_viz.sh\n",
      "../utils\n",
      "../__pycache__\n",
      "../load_hapaxes.py\n",
      "../Project History.pdf\n",
      "../explore\n",
      "../README.md\n",
      "../load_ngram_intersects.py\n",
      "../load_hapax_intersects.py\n",
      "../load_ngrams.py\n",
      "../.gitignore\n",
      "../arch\n",
      "../.venv\n",
      "../load_alignments.py\n",
      "../make_jumbo_dash.py\n",
      "../begin.sh\n",
      "../load_authors_and_texts.py\n",
      "../hapaxes_1tM.py\n",
      "../make_auto_scatterplot.py\n",
      "../show_previous_averages.py\n",
      "../make_3d_plot.py\n",
      "../poetry.lock\n",
      "../.git\n",
      "../load_relationships.py\n",
      "../authors.txt\n",
      "../make_histogram.py\n",
      "../notebooks\n",
      "../do_svm.py\n",
      "../.current_project\n",
      "../init_db.py\n"
     ]
    }
   ],
   "source": [
    "for thing in things:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:35.564842Z",
     "iopub.status.busy": "2024-05-01T15:11:35.564410Z",
     "iopub.status.idle": "2024-05-01T15:11:35.568461Z",
     "shell.execute_reply": "2024-05-01T15:11:35.567841Z",
     "shell.execute_reply.started": "2024-05-01T15:11:35.564817Z"
    }
   },
   "outputs": [],
   "source": [
    "project_name = 'sm-test'\n",
    "project_path = working / 'projects' / project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:35.923430Z",
     "iopub.status.busy": "2024-05-01T15:11:35.923045Z",
     "iopub.status.idle": "2024-05-01T15:11:35.928703Z",
     "shell.execute_reply": "2024-05-01T15:11:35.928113Z",
     "shell.execute_reply.started": "2024-05-01T15:11:35.923403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../projects/sm-test')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:36.350146Z",
     "iopub.status.busy": "2024-05-01T15:11:36.349826Z",
     "iopub.status.idle": "2024-05-01T15:11:36.354400Z",
     "shell.execute_reply": "2024-05-01T15:11:36.353656Z",
     "shell.execute_reply.started": "2024-05-01T15:11:36.350118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../projects/sm-test/db/svm.db')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path = project_path / 'db' / f'{project_name}.db'\n",
    "svm_db_path = project_path / 'db' / 'svm.db'\n",
    "db_path\n",
    "svm_db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:36.640474Z",
     "iopub.status.busy": "2024-05-01T15:11:36.640122Z",
     "iopub.status.idle": "2024-05-01T15:11:36.644501Z",
     "shell.execute_reply": "2024-05-01T15:11:36.643965Z",
     "shell.execute_reply.started": "2024-05-01T15:11:36.640451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:36.946367Z",
     "iopub.status.busy": "2024-05-01T15:11:36.946048Z",
     "iopub.status.idle": "2024-05-01T15:11:36.953343Z",
     "shell.execute_reply": "2024-05-01T15:11:36.952070Z",
     "shell.execute_reply.started": "2024-05-01T15:11:36.946346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the EDGES_QUERY template with placeholders for weight_id and threshold\n",
    "EDGES_QUERY_TEMPLATE = \"\"\"\n",
    "WITH RankedResults AS (\n",
    "    SELECT \n",
    "        calculation.pair_id,\n",
    "        round(calculation.comp_score, 3) as comp_score,\n",
    "        calculation.threshold,\n",
    "        weight.weight_id,\n",
    "        weight.hap_weight,\n",
    "        weight.al_weight,\n",
    "        weight.svm_weight,\n",
    "        combined_jaccard.hap_jac_dis,\n",
    "        combined_jaccard.hap_jac_sim,\n",
    "        combined_jaccard.al_jac_dis,\n",
    "        combined_jaccard.al_jac_sim,\n",
    "        text_pair.text_a AS a_text_id,\n",
    "        text_pair.text_b AS b_text_id,\n",
    "        text_a.source_filename AS a_text_filename,\n",
    "        text_b.source_filename AS b_text_filename,\n",
    "        text_a.chapter_num AS a_chap_num,\n",
    "        text_b.chapter_num AS b_chap_num,\n",
    "        dir_a.id AS a_work_dir_id,\n",
    "        dir_b.id AS b_work_dir_id,\n",
    "        dir_a.dir AS a_work,\n",
    "        dir_b.dir AS b_work,\n",
    "        text_a.author_id AS a_author_id,\n",
    "        text_b.author_id AS b_author_id,\n",
    "        text_a.short_name_for_svm AS a_short,\n",
    "        text_b.short_name_for_svm AS b_short,\n",
    "        calculation.same_author,\n",
    "        author_a.author_name AS a_author,\n",
    "        author_b.author_name AS b_author,\n",
    "        ROW_NUMBER() OVER (PARTITION BY weight.weight_id, calculation.threshold ORDER BY calculation.pair_id) as row_num,\n",
    "        RANDOM() as rand_val\n",
    "    FROM calculations AS calculation\n",
    "    JOIN text_pairs AS text_pair ON text_pair.id = calculation.pair_id\n",
    "    JOIN weights AS weight ON weight.weight_id = calculation.weight_id\n",
    "    JOIN all_texts AS text_a ON text_a.text_id = text_pair.text_a\n",
    "    JOIN all_texts AS text_b ON text_b.text_id = text_pair.text_b\n",
    "    JOIN dirs AS dir_a ON dir_a.id = text_a.dir\n",
    "    JOIN dirs AS dir_b ON dir_b.id = text_b.dir\n",
    "    JOIN authors AS author_a ON author_a.id = text_a.author_id\n",
    "    JOIN authors AS author_b ON author_b.id = text_b.author_id\n",
    "    JOIN combined_jaccard ON combined_jaccard.pair_id = calculation.pair_id\n",
    "    WHERE weight.weight_id = {weight_id}\n",
    "      AND calculation.threshold >= {threshold}\n",
    "      AND dir_a.id <> dir_b.id\n",
    "    ORDER BY rand_val\n",
    ")\n",
    "SELECT *\n",
    "FROM RankedResults\n",
    "ORDER BY weight_id, pair_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:37.252000Z",
     "iopub.status.busy": "2024-05-01T15:11:37.251665Z",
     "iopub.status.idle": "2024-05-01T15:11:37.256647Z",
     "shell.execute_reply": "2024-05-01T15:11:37.255866Z",
     "shell.execute_reply.started": "2024-05-01T15:11:37.251980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWITH RankedResults AS (\\n    SELECT \\n        calculation.pair_id,\\n        round(calculation.comp_score, 3) as comp_score,\\n        calculation.threshold,\\n        weight.weight_id,\\n        weight.hap_weight,\\n        weight.al_weight,\\n        weight.svm_weight,\\n        combined_jaccard.hap_jac_dis,\\n        combined_jaccard.hap_jac_sim,\\n        combined_jaccard.al_jac_dis,\\n        combined_jaccard.al_jac_sim,\\n        text_pair.text_a AS a_text_id,\\n        text_pair.text_b AS b_text_id,\\n        text_a.source_filename AS a_text_filename,\\n        text_b.source_filename AS b_text_filename,\\n        text_a.chapter_num AS a_chap_num,\\n        text_b.chapter_num AS b_chap_num,\\n        dir_a.id AS a_work_dir_id,\\n        dir_b.id AS b_work_dir_id,\\n        dir_a.dir AS a_work,\\n        dir_b.dir AS b_work,\\n        text_a.author_id AS a_author_id,\\n        text_b.author_id AS b_author_id,\\n        text_a.short_name_for_svm AS a_short,\\n        text_b.short_name_for_svm AS b_short,\\n        calculation.same_author,\\n        author_a.author_name AS a_author,\\n        author_b.author_name AS b_author,\\n        ROW_NUMBER() OVER (PARTITION BY weight.weight_id, calculation.threshold ORDER BY calculation.pair_id) as row_num,\\n        RANDOM() as rand_val\\n    FROM calculations AS calculation\\n    JOIN text_pairs AS text_pair ON text_pair.id = calculation.pair_id\\n    JOIN weights AS weight ON weight.weight_id = calculation.weight_id\\n    JOIN all_texts AS text_a ON text_a.text_id = text_pair.text_a\\n    JOIN all_texts AS text_b ON text_b.text_id = text_pair.text_b\\n    JOIN dirs AS dir_a ON dir_a.id = text_a.dir\\n    JOIN dirs AS dir_b ON dir_b.id = text_b.dir\\n    JOIN authors AS author_a ON author_a.id = text_a.author_id\\n    JOIN authors AS author_b ON author_b.id = text_b.author_id\\n    JOIN combined_jaccard ON combined_jaccard.pair_id = calculation.pair_id\\n    WHERE weight.weight_id = {weight_id}\\n      AND calculation.threshold >= {threshold}\\n      AND dir_a.id <> dir_b.id\\n    ORDER BY rand_val\\n)\\nSELECT *\\nFROM RankedResults\\nORDER BY weight_id, pair_id\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDGES_QUERY_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:37.651568Z",
     "iopub.status.busy": "2024-05-01T15:11:37.651281Z",
     "iopub.status.idle": "2024-05-01T15:11:37.655242Z",
     "shell.execute_reply": "2024-05-01T15:11:37.654737Z",
     "shell.execute_reply.started": "2024-05-01T15:11:37.651549Z"
    }
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_path)\n",
    "# Cleanup any edges that might already exist.\n",
    "con.execute(\"DROP TABLE IF EXISTS edges\")\n",
    "con.commit()\n",
    "con.execute(\"DROP VIEW IF EXISTS edges\")\n",
    "con.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to create the initial dataframe to work with that pulls everything but the SVM values into a CSV to store the dataframe for rapidity of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:38.058632Z",
     "iopub.status.busy": "2024-05-01T15:11:38.058086Z",
     "iopub.status.idle": "2024-05-01T15:11:38.063769Z",
     "shell.execute_reply": "2024-05-01T15:11:38.062844Z",
     "shell.execute_reply.started": "2024-05-01T15:11:38.058604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the CSV file\n",
    "csv_file_path = project_path / f'{project_name}-initial.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(csv_file_path):\n",
    "    # Load the DataFrame from the CSV file\n",
    "    edges_df = pd.read_csv(csv_file_path)\n",
    "    print(\"Loaded DataFrame from CSV file.\")\n",
    "else:\n",
    "    # Create an in-memory database and load the necessary tables\n",
    "    memory_con = sqlite3.connect(':memory:')\n",
    "    with memory_con:\n",
    "        con.backup(memory_con)\n",
    "\n",
    "    # Fetch unique weight_ids from the database\n",
    "    weight_ids_query = \"SELECT DISTINCT weight_id FROM weights\"\n",
    "    weight_ids_df = pd.read_sql(weight_ids_query, memory_con)\n",
    "    weight_ids = weight_ids_df['weight_id'].tolist()\n",
    "\n",
    "    # Fetch unique thresholds from the database\n",
    "    thresholds_query = \"SELECT DISTINCT threshold FROM calculations\"\n",
    "    thresholds_df = pd.read_sql(thresholds_query, memory_con)\n",
    "    thresholds = thresholds_df['threshold'].tolist()\n",
    "\n",
    "    # Create a list of tuples combining weights and thresholds\n",
    "    combinations = [(weight_id, threshold) for weight_id in weight_ids for threshold in thresholds]\n",
    "    print(\"Weight/Threshold Combos. Can delete: \", combinations)\n",
    "\n",
    "    # Prepare to collect data for the edges DataFrame\n",
    "    edges_data = []\n",
    "\n",
    "    total_iterations = len(weight_ids) * len(thresholds)\n",
    "\n",
    "    with tqdm(total=total_iterations, desc=\"Processing\") as pbar:\n",
    "        for weight_id, threshold in combinations:\n",
    "            # Format the query with the current weight_id and threshold\n",
    "            formatted_query = EDGES_QUERY_TEMPLATE.format(weight_id=weight_id, threshold=threshold)\n",
    "                \n",
    "            # Print the formatted query to check for syntax issues\n",
    "            print(formatted_query)\n",
    "            \n",
    "            df = pd.read_sql(formatted_query, memory_con)\n",
    "            edges_data.append(df)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    # Concatenate all the DataFrames into one\n",
    "    edges_df = pd.concat(edges_data, ignore_index=True)\n",
    "\n",
    "    # Save the final DataFrame to a CSV file\n",
    "    edges_df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Saved DataFrame to {csv_file_path}\")\n",
    "\n",
    "    # Close the database connections\n",
    "    memory_con.close()\n",
    "    con.close()\n",
    "\n",
    "# Display the final DataFrame\n",
    "#print(edges_df.sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0e464dc7b84648a594ace7b6701ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating SVM Scores:   0%|          | 0/3067632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame with SVM scores to ../projects/sm-test/sm-test-with-svm.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the CSV file for edges_df with SVM scores\n",
    "svm_csv_file_path = project_path / f'{project_name}-with-svm.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(svm_csv_file_path):\n",
    "    # Load the DataFrame from the CSV file\n",
    "    edges_df = pd.read_csv(svm_csv_file_path)\n",
    "    print(\"Loaded DataFrame with SVM scores from CSV file.\")\n",
    "else:\n",
    "    # Connect to the SVM database and create an in-memory database\n",
    "    svm_con = sqlite3.connect(svm_db_path)\n",
    "    memory_con = sqlite3.connect(':memory:')\n",
    "    with memory_con:\n",
    "        svm_con.backup(memory_con)\n",
    "    memory_con.execute(\"CREATE INDEX nov_num_idx ON chapter_assessments(novel, number);\")\n",
    "\n",
    "    def get_svm_score(a_short, a_chap_num, b_short):\n",
    "        query = f\"\"\"\n",
    "        SELECT {b_short} AS svm_score\n",
    "        FROM chapter_assessments\n",
    "        WHERE novel = ?\n",
    "        AND number = ?\n",
    "        \"\"\"\n",
    "        \n",
    "        result = pd.read_sql(query, memory_con, params=(a_short, a_chap_num))\n",
    "        \n",
    "        if not result.empty:\n",
    "            return result['svm_score'].iloc[0]\n",
    "        return None\n",
    "\n",
    "    # Initialize tqdm to monitor progress\n",
    "    tqdm.pandas(desc=\"Calculating SVM Scores\")\n",
    "\n",
    "    # Apply the function to each row in edges_df\n",
    "    edges_df['svm_score'] = edges_df.progress_apply(lambda row: get_svm_score(row['a_short'], row['a_chap_num'], row['b_short']), axis=1)\n",
    "\n",
    "    # Save the final DataFrame to a CSV file\n",
    "    edges_df.to_csv(svm_csv_file_path, index=False)\n",
    "    print(f\"Saved DataFrame with SVM scores to {svm_csv_file_path}\")\n",
    "\n",
    "    # Close the connection to svm.db and memory con\n",
    "    memory_con.close()\n",
    "    svm_con.close()\n",
    "\n",
    "# Display the final DataFrame with SVM scores\n",
    "#print(edges_df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is a quick check on columns; can be commented out or not as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:38.817091Z",
     "iopub.status.busy": "2024-05-01T15:11:38.816572Z",
     "iopub.status.idle": "2024-05-01T15:11:44.636785Z",
     "shell.execute_reply": "2024-05-01T15:11:44.636532Z",
     "shell.execute_reply.started": "2024-05-01T15:11:38.817070Z"
    }
   },
   "outputs": [],
   "source": [
    "# #edges_df = pd.read_sql(df_query, con)\n",
    "# print(f\"{len(edges_df):,}\")\n",
    "# print(edges_df.sample(n=100, random_state=42))\n",
    "# columns_list = edges_df.columns.tolist()\n",
    "# print(columns_list)\n",
    "# print(len(edges_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is for diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: This is just here so we can see all the columns. Delete when sure it works.\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# display(edges_df)\n",
    "# print(len(edges_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is diagnostic; making sure all results are showing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:44.637590Z",
     "iopub.status.busy": "2024-05-01T15:11:44.637517Z",
     "iopub.status.idle": "2024-05-01T15:11:44.699945Z",
     "shell.execute_reply": "2024-05-01T15:11:44.699678Z",
     "shell.execute_reply.started": "2024-05-01T15:11:44.637582Z"
    }
   },
   "outputs": [],
   "source": [
    "# # SOLVED A way to choose whether to exclude a piece of a work from connecting to itself (e.g. Trollope 1840 ch 10, ibid ch 20) (solved in SQL)\n",
    "\n",
    "# #A way to visibly toggle the thresholds to fine-grainedly shade edges and possibly connect them closer\n",
    "\n",
    "# #A way to only display desired authors all the way down to one\n",
    "# #A way to visibly toggle the weights\n",
    "# #A way to light up nodes above a certain threshold even if lower thresholds are displayed\n",
    "# #use pandas to group by work so individual book can be displayed on the graph below. \n",
    "# #check that all four results in same_author are showing up (yes, no, false positive, false negative)\n",
    "\n",
    "# #edges_df = edges_df.sample(1000)\n",
    "# print(len(edges_df))\n",
    "# min_comp_score = edges_df['comp_score'].min() \n",
    "# max_comp_score = edges_df['comp_score'].max() \n",
    "# print(min_comp_score, max_comp_score)\n",
    "\n",
    "# # Filter the DataFrame for rows where 'same_author' equals 'yes'\n",
    "# print(edges_df[edges_df['same_author'] == 'Yes'].head(10))\n",
    "# # Filter the DataFrame for rows where 'same_author' equals 'no'\n",
    "# print(edges_df[edges_df['same_author'] == 'No'].head(10))\n",
    "# # Filter the DataFrame for rows where 'same_author' equals 'false_positive'\n",
    "# print(edges_df[edges_df['same_author'] == 'False Positive'].head(10))\n",
    "# # Filter the DataFrame for rows where 'same_author' equals 'false_negative'\n",
    "# print(edges_df[edges_df['same_author'] == 'False Negative'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the logistic regression logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarahmarie/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/tarahmarie/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/tarahmarie/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create and train the logistic regression model with balanced class weights\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m     24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/ONGOING-Oxford/OxfordTree/oxford_uni/dh-trace/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Load your data into a DataFrame (assuming it's already done)\n",
    "# edges_df = pd.read_sql(df_query, con)\n",
    "\n",
    "# While testing, limit to 10000 edges or this will take forever.\n",
    "edges_df = edges_df.sample(10000)\n",
    "\n",
    "# Select relevant features and target\n",
    "features = ['hap_jac_sim', 'al_jac_sim', 'svm_score']\n",
    "X = edges_df[features]\n",
    "y = edges_df['same_author']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model with balanced class weights\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Plot confusion matrix with labels\n",
    "labels = ['Different Author', 'Same Author']\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Coefficients of the model\n",
    "print(\"Model coefficients (weights for the features):\")\n",
    "for feature, coef in zip(features, model.coef_[0]):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is all the graphing code. It's commented out for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:44.700345Z",
     "iopub.status.busy": "2024-05-01T15:11:44.700275Z",
     "iopub.status.idle": "2024-05-01T15:11:44.704063Z",
     "shell.execute_reply": "2024-05-01T15:11:44.703830Z",
     "shell.execute_reply.started": "2024-05-01T15:11:44.700338Z"
    }
   },
   "outputs": [],
   "source": [
    "# G = nx.from_pandas_edgelist(\n",
    "#     edges_df,\n",
    "#     source = 'a_text_filename',\n",
    "#     target = 'b_text_filename',\n",
    "#     edge_attr = ['comp_score'],\n",
    "#     create_using = nx.DiGraph)\n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edges_df.sample(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:44.705178Z",
     "iopub.status.busy": "2024-05-01T15:11:44.705107Z",
     "iopub.status.idle": "2024-05-01T15:11:44.707408Z",
     "shell.execute_reply": "2024-05-01T15:11:44.707162Z",
     "shell.execute_reply.started": "2024-05-01T15:11:44.705172Z"
    }
   },
   "outputs": [],
   "source": [
    "#G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:44.707763Z",
     "iopub.status.busy": "2024-05-01T15:11:44.707693Z",
     "iopub.status.idle": "2024-05-01T15:11:44.709407Z",
     "shell.execute_reply": "2024-05-01T15:11:44.709187Z",
     "shell.execute_reply.started": "2024-05-01T15:11:44.707756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEXT_FONT_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:44.709759Z",
     "iopub.status.busy": "2024-05-01T15:11:44.709694Z",
     "iopub.status.idle": "2024-05-01T15:11:54.495044Z",
     "shell.execute_reply": "2024-05-01T15:11:54.494675Z",
     "shell.execute_reply.started": "2024-05-01T15:11:44.709752Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Position nodes using Fruchterman-Reingold force-directed algorithm\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "#  # Draw nodes with labels\n",
    "# nx.draw(G, width=1, node_size=500, node_color='salmon', with_labels=True)\n",
    "# # Draw edges with arrows and labels\n",
    "# edge_labels = nx.get_edge_attributes(G, 'comp_score')\n",
    "# _ = nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='blue', font_size=TEXT_FONT_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:54.495983Z",
     "iopub.status.busy": "2024-05-01T15:11:54.495800Z",
     "iopub.status.idle": "2024-05-01T15:11:56.146141Z",
     "shell.execute_reply": "2024-05-01T15:11:56.145815Z",
     "shell.execute_reply.started": "2024-05-01T15:11:54.495972Z"
    }
   },
   "outputs": [],
   "source": [
    "# C = CytoscapeWidget()\n",
    "# #C.set_layout(name='cola')\n",
    "# C.set_layout(name='dagre', rankDir='LR', spacingFactor=3)\n",
    "# C.graph.add_graph_from_networkx(G, directed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:56.146774Z",
     "iopub.status.busy": "2024-05-01T15:11:56.146702Z",
     "iopub.status.idle": "2024-05-01T15:11:56.150184Z",
     "shell.execute_reply": "2024-05-01T15:11:56.149905Z",
     "shell.execute_reply.started": "2024-05-01T15:11:56.146764Z"
    }
   },
   "outputs": [],
   "source": [
    "# #this is so we can programmatically edit and choose variables for the graph\n",
    "\n",
    "# def build_style(color_threshold):\n",
    "#     return [\n",
    "#         {\n",
    "#              'selector': 'node',\n",
    "#              'style': {\n",
    "#                  'background-color': 'salmon',\n",
    "#                  'font-family': 'helvetica',\n",
    "#                  'font-size': f\"{TEXT_FONT_SIZE}px\",\n",
    "#                  'label': 'data(id)'\n",
    "#              }\n",
    "#         },\n",
    "#         {\n",
    "#              'selector': 'edge',\n",
    "#              'style': {\n",
    "#                  'line-color': 'black',\n",
    "#                  'font-family': 'helvetica',\n",
    "#                  'font-size': f\"{TEXT_FONT_SIZE}px\",\n",
    "#                  'color': 'blue',\n",
    "#                  'label': 'data(comp_score)',\n",
    "#                 'width': f\"mapData(comp_score, {min_comp_score}, {max_comp_score}, 1, 10)\"\n",
    "#                  #'width': '10px',\n",
    "#              }\n",
    "#         },\n",
    "#         {\n",
    "#             \"selector\": \"edge.directed\",\n",
    "#             \"style\": {\n",
    "#                 \"curve-style\": \"bezier\",\n",
    "#                 \"target-arrow-shape\": \"triangle\",\n",
    "#                 \"target-arrow-color\": \"black\",\n",
    "#             }\n",
    "#         }, \n",
    "#         {\n",
    "#             \"selector\": f\"edge[comp_score>{color_threshold}]\",\n",
    "#             \"style\": {\n",
    "#                 \"line-color\": \"red\",\n",
    "#             }\n",
    "#         },\n",
    "#     ]\n",
    "# style = build_style(0.92)\n",
    "# pprint(style)\n",
    "# C.set_style(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:56.150772Z",
     "iopub.status.busy": "2024-05-01T15:11:56.150697Z",
     "iopub.status.idle": "2024-05-01T15:11:56.155152Z",
     "shell.execute_reply": "2024-05-01T15:11:56.154882Z",
     "shell.execute_reply.started": "2024-05-01T15:11:56.150765Z"
    }
   },
   "outputs": [],
   "source": [
    "# #make slider\n",
    "\n",
    "# caption = widgets.Label(value='The slider value is in its initial position.')\n",
    "\n",
    "# slider = widgets.IntSlider(\n",
    "#     value=90,\n",
    "#     min=90,\n",
    "#     max=100,\n",
    "#     step=1,\n",
    "#     description='Test:',\n",
    "#     disabled=False,\n",
    "#     continuous_update=False,\n",
    "#     orientation='horizontal',\n",
    "#     readout=True,\n",
    "#     readout_format='d'\n",
    "# )\n",
    "# def handle_slider_change(change):\n",
    "#     color_threshold = change.new / 100\n",
    "#     caption.value = f\"The slider value is: {color_threshold}\"\n",
    "#     style = build_style(color_threshold=color_threshold)\n",
    "#     C.set_style(style)\n",
    "    \n",
    "# slider.observe(handle_slider_change, names='value')\n",
    "# display(caption, slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:11:56.158547Z",
     "iopub.status.busy": "2024-05-01T15:11:56.158490Z",
     "iopub.status.idle": "2024-05-01T15:11:56.175175Z",
     "shell.execute_reply": "2024-05-01T15:11:56.174948Z",
     "shell.execute_reply.started": "2024-05-01T15:11:56.158541Z"
    }
   },
   "outputs": [],
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:12:13.280532Z",
     "iopub.status.busy": "2024-05-01T15:12:13.279970Z",
     "iopub.status.idle": "2024-05-01T15:12:13.433944Z",
     "shell.execute_reply": "2024-05-01T15:12:13.433399Z",
     "shell.execute_reply.started": "2024-05-01T15:12:13.280501Z"
    }
   },
   "source": [
    " # MOVE OVER TO CYTOSCAPE APP FOR STRETCHY THINGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:13:12.163420Z",
     "iopub.status.busy": "2024-05-01T15:13:12.162966Z",
     "iopub.status.idle": "2024-05-01T15:13:12.513863Z",
     "shell.execute_reply": "2024-05-01T15:13:12.512479Z",
     "shell.execute_reply.started": "2024-05-01T15:13:12.163394Z"
    }
   },
   "outputs": [],
   "source": [
    "# p4c.cytoscape_ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:13:37.163623Z",
     "iopub.status.busy": "2024-05-01T15:13:37.163094Z",
     "iopub.status.idle": "2024-05-01T15:13:37.198537Z",
     "shell.execute_reply": "2024-05-01T15:13:37.197082Z",
     "shell.execute_reply.started": "2024-05-01T15:13:37.163595Z"
    }
   },
   "outputs": [],
   "source": [
    "# p4c.cytoscape_version_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T15:13:54.735862Z",
     "iopub.status.busy": "2024-05-01T15:13:54.735366Z",
     "iopub.status.idle": "2024-05-01T15:13:55.744710Z",
     "shell.execute_reply": "2024-05-01T15:13:55.744055Z",
     "shell.execute_reply.started": "2024-05-01T15:13:54.735831Z"
    }
   },
   "outputs": [],
   "source": [
    "# p4c.create_network_from_networkx(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
